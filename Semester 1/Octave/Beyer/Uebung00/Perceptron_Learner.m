% Matlab code of Perceptron Learning Algorithm %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% % Copyright by Hans-Georg Beyer (HGB). For teaching use only! It is % not allowed to use this program without written permission by HGB %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% function [w, n_w_changes, n_iter, n_misclassified, w_found, w_history] = Perceptron_Learner(x, d, max_iter = 1000)  % input x: made of K feature row vectors of dimension M  % input d = {-1,1}^K: column vector of dimension K  % output w: (normalized) weight vector the M+1st component is theta  % output n_w_changes: number of weight changes  % output n_iter: number of for-loop cycles  % output n_misclassified: dynamics of number of misclassified data  [K, M] =size(x);  w = rand(1, M+1);   phi=x;   phi(:,M+1)=ones(K,1);   n_w_changes = 0;   n_misclassified = [];   w_found = 0;  w_history = [];  for n_iter=1:max_iter    n_miscl = 0;     for k=1:K      if (sign( w*phi(k,:)') != d(k))         w = w + d(k)*phi(k,:);         n_w_changes = n_w_changes + 1;         n_miscl = n_miscl + 1;      end     end    n_misclassified(n_iter) = sum((d' != sign( w*phi' )));    w_history = [w_history; w/norm(w)];    if (n_miscl == 0)       w_found = 1;      break;    end   end  w = w/norm(w); end % function